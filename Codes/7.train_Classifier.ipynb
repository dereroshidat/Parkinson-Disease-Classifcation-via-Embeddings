{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "476e26ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c66724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM  bal-acc: 1.0 macro-F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "PATH = '/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/HC_h_fusion/hc_fused_readtext.npz'\n",
    "\n",
    "data = np.load(PATH, allow_pickle=False)\n",
    "X, y, ids = data[\"X\"], data[\"y\"], data[\"ids\"]\n",
    "\n",
    "# split by patient if multiple recordings per patient (derive patient key from id string)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# SVM (RBF) – needs scaling\n",
    "svm = make_pipeline(StandardScaler(with_mean=True, with_std=True),\n",
    "                    SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", class_weight=\"balanced\"))\n",
    "svm.fit(Xtr, ytr)\n",
    "yp = svm.predict(Xte)\n",
    "print(\"SVM  bal-acc:\", balanced_accuracy_score(yte, yp), \"macro-F1:\", f1_score(yte, yp, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd8c8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF   bal-acc: 1.0 macro-F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "# RandomForest – scaling not necessary\n",
    "rf = RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", max_depth=None, random_state=42)\n",
    "rf.fit(Xtr, ytr)\n",
    "yp = rf.predict(Xte)\n",
    "print(\"RF   bal-acc:\", balanced_accuracy_score(yte, yp), \"macro-F1:\", f1_score(yte, yp, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4663af",
   "metadata": {},
   "source": [
    "# to check the credibility of the evaluation result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00620391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupCV bal-acc mean±sd: 1.0 ± 0.0\n",
      "GroupCV macro-F1 mean±sd: 1.0 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "import re, numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "\n",
    "# load fused\n",
    "data = np.load(PATH, allow_pickle=False)\n",
    "X, y, ids = data[\"X\"], data[\"y\"], data[\"ids\"]\n",
    "\n",
    "# patient id (e.g., \"ID00_hc_...\" -> \"ID00\")\n",
    "patients = np.array([re.split(r'[_]', i)[0] for i in ids])\n",
    "\n",
    "cv = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "svm = make_pipeline(StandardScaler(with_mean=True), SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", class_weight=\"balanced\"))\n",
    "\n",
    "ba, f1 = [], []\n",
    "for tr, te in cv.split(X, y, groups=patients):\n",
    "    svm.fit(X[tr], y[tr])\n",
    "    yp = svm.predict(X[te])\n",
    "    ba.append(balanced_accuracy_score(y[te], yp))\n",
    "    f1.append(f1_score(y[te], yp, average=\"macro\"))\n",
    "print(\"GroupCV bal-acc mean±sd:\", np.mean(ba), \"±\", np.std(ba))\n",
    "print(\"GroupCV macro-F1 mean±sd:\", np.mean(f1), \"±\", np.std(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8091a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutation bal-acc (should be ~0.5): 0.7485119047619048\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "y_shuf = rng.permutation(y)\n",
    "svm = make_pipeline(StandardScaler(), SVC(kernel=\"rbf\", class_weight=\"balanced\"))\n",
    "svm.fit(X, y_shuf)\n",
    "print(\"Permutation bal-acc (should be ~0.5):\",\n",
    "      balanced_accuracy_score(y_shuf, svm.predict(X)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee1239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0]\n",
      " [0 4]]\n",
      "Test size: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# after one CV fold:\n",
    "print(confusion_matrix(y[te], yp))\n",
    "print(\"Test size:\", len(te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786fbcf6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ee64d8f",
   "metadata": {},
   "source": [
    "# External Validation\n",
    "\n",
    "\n",
    "I want to train the entire readText  and will use the entire spontaneous fusion for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7867227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM  bal-acc: 0.5 macro-F1: 0.3076923076923077\n"
     ]
    }
   ],
   "source": [
    "Train_PATH = '/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/HC_h_fusion/hc_fused_readtext.npz'\n",
    "\n",
    "train_data = np.load(Train_PATH, allow_pickle=False)\n",
    "X, y, ids = train_data[\"X\"], train_data[\"y\"], train_data[\"ids\"]\n",
    "\n",
    "Test_path = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/spontaneous_h_fusion/spontaneous_fused_readtext.npz\"\n",
    "test_data = np.load(Test_path, allow_pickle=False)\n",
    "Xtest, ytest, idstest = test_data[\"X\"], test_data[\"y\"], test_data[\"ids\"]\n",
    "\n",
    "# SVM (RBF) – needs scaling\n",
    "svm = make_pipeline(StandardScaler(with_mean=True, with_std=True),\n",
    "                    SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", class_weight=\"balanced\"))\n",
    "svm.fit(X, y)\n",
    "yp = svm.predict(Xtest)\n",
    "print(\"SVM  bal-acc:\", balanced_accuracy_score(ytest, yp), \"macro-F1:\", f1_score(ytest, yp, average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74cb9da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF   bal-acc: 0.55 macro-F1: 0.4109090909090909\n"
     ]
    }
   ],
   "source": [
    "# RandomForest – scaling not necessary\n",
    "rf = RandomForestClassifier(n_estimators=400, class_weight=\"balanced\", max_depth=None, random_state=42)\n",
    "rf.fit(X, y)\n",
    "yp = rf.predict(Xtest)\n",
    "print(\"RF   bal-acc:\", balanced_accuracy_score(ytest, yp), \"macro-F1:\", f1_score(ytest, yp, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c224078",
   "metadata": {},
   "source": [
    "# Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dec23f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_only   | BA 0.500 | F1 0.308\n",
      "audio_only  | BA 0.500 | F1 0.308\n",
      "clip_only   | BA 0.500 | F1 0.308\n",
      "text+audio  | BA 0.500 | F1 0.308\n",
      "text+clip   | BA 0.500 | F1 0.308\n",
      "audio+clip  | BA 0.500 | F1 0.308\n",
      "all_three   | BA 0.500 | F1 0.308\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, re\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "\n",
    "# Load the two fused files you created\n",
    "src = np.load(\"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/HC_h_fusion/hc_fused_readtext.npz\", allow_pickle=False)\n",
    "tgt = np.load(\"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/spontaneous_h_fusion/spontaneous_fused_readtext.npz\", allow_pickle=False)\n",
    "\n",
    "X_src, y_src = src[\"X\"], src[\"y\"]\n",
    "X_tgt, y_tgt = tgt[\"X\"], tgt[\"y\"]\n",
    "D_TEXT, D_AUDIO, D_CLIP = int(src[\"D_text\"]), int(src[\"D_audio\"]), int(src[\"D_graph\"])\n",
    "\n",
    "sl_text  = slice(0, D_TEXT)\n",
    "sl_audio = slice(D_TEXT, D_TEXT + D_AUDIO)\n",
    "sl_clip  = slice(D_TEXT + D_AUDIO, D_TEXT + D_AUDIO + D_CLIP)\n",
    "\n",
    "svm = make_pipeline(StandardScaler(with_mean=True, with_std=True),\n",
    "                    SVC(kernel=\"rbf\", C=1.0, gamma=\"scale\", class_weight=\"balanced\"))\n",
    "\n",
    "def eval_one(slices):\n",
    "    Xs = np.concatenate([X_src[:, s] for s in slices], axis=1)\n",
    "    Xt = np.concatenate([X_tgt[:, s] for s in slices], axis=1)\n",
    "    model = svm.fit(Xs, y_src)\n",
    "    yp = model.predict(Xt)\n",
    "    return (balanced_accuracy_score(y_tgt, yp),\n",
    "            f1_score(y_tgt, yp, average=\"macro\"))\n",
    "\n",
    "for name, sls in {\n",
    "    \"text_only\":[sl_text], \"audio_only\":[sl_audio], \"clip_only\":[sl_clip],\n",
    "    \"text+audio\":[sl_text, sl_audio], \"text+clip\":[sl_text, sl_clip],\n",
    "    \"audio+clip\":[sl_audio, sl_clip], \"all_three\":[sl_text, sl_audio, sl_clip],\n",
    "}.items():\n",
    "    ba, f1 = eval_one(sls)\n",
    "    print(f\"{name:11s} | BA {ba:.3f} | F1 {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85520bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheedah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
