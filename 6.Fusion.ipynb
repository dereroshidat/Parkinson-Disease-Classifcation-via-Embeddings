{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decacfb2",
   "metadata": {},
   "source": [
    "# This is the method I use for fusion now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed0b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff208ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np\n",
    "\n",
    "def read_filenames_any_encoding(path):\n",
    "    # Read raw bytes\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    # BOM sniff\n",
    "    if data.startswith(b\"\\xff\\xfe\"):\n",
    "        enc = \"utf-16-le\"\n",
    "    elif data.startswith(b\"\\xfe\\xff\"):\n",
    "        enc = \"utf-16-be\"\n",
    "    elif data.startswith(b\"\\xef\\xbb\\xbf\"):\n",
    "        enc = \"utf-8-sig\"\n",
    "    else:\n",
    "        # try utf-8, else fall back to latin-1\n",
    "        try:\n",
    "            data.decode(\"utf-8\")\n",
    "            enc = \"utf-8\"\n",
    "        except UnicodeDecodeError:\n",
    "            enc = \"latin-1\"\n",
    "    text = data.decode(enc, errors=\"strict\")\n",
    "    return [ln.strip() for ln in text.splitlines() if ln.strip()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e51c996",
   "metadata": {},
   "source": [
    "# Fusing all embeddings for ReadText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "670ccee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts — text: 37 audio: 37 clip: 37\n",
      "common ids: 37\n",
      "Saved: /mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/HC_h_fusion/hc_fused_readtext.npz | X: (37, 2048) | HC: 21 PD: 16\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob, numpy as np\n",
    "\n",
    "# ---- paths (ReadText only) ----\n",
    "HC_READTEXT_NPZ = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/h_graph_selfattn/HC_ReadText_Spectrogram_CLIP_features_h_graph_selfattn.npz\"\n",
    "HC_READTEXT_TXT = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/CLIP_Spectrogram_embeddings/HC_ReadText_Spectrogram_CLIP_filenames.txt\"\n",
    "PD_READTEXT_NPZ = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/h_graph_selfattn/PD_ReadText_Spectrogram_CLIP_features_h_graph_selfattn.npz\"\n",
    "PD_READTEXT_TXT = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/CLIP_Spectrogram_embeddings/PD_ReadText_Spectrogram_CLIP_filenames.txt\"\n",
    "\n",
    "HC_TEXT_DIR  = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/Transcript_Self_Attention/hc_ReadText_selfattn\"\n",
    "PD_TEXT_DIR  = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/Transcript_Self_Attention/PD_ReadText_selfattn\"\n",
    "HC_AUDIO_DIR = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/audio_self_attention/HC_ReadText_h_audio_selfattn\"\n",
    "PD_AUDIO_DIR = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/audio_self_attention/PD_ReadText_h_audio_selfattn\"\n",
    "\n",
    "OUT_PATH = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/HC_h_fusion/hc_fused_readtext.npz\"\n",
    "os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
    "\n",
    "D_TEXT, D_AUDIO, D_CLIP = 768, 768, 512\n",
    "\n",
    "# ---- utils ----\n",
    "suffix_re = re.compile(\n",
    "    r\"_(?:h_text(?:_.*)?|h_audio(?:_.*)?|h_graph(?:_.*)?|h_clip(?:_.*)?|hubert_feats|audio_feats|tokens_for_selfattn)$\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "def base_id_from_name(name: str) -> str:\n",
    "    base = os.path.splitext(os.path.basename(str(name)))[0]\n",
    "    return suffix_re.sub(\"\", base)\n",
    "\n",
    "def map_ids(folder):\n",
    "    paths = glob.glob(os.path.join(folder, \"*.npz\")) + glob.glob(os.path.join(folder, \"*.npy\"))\n",
    "    return {base_id_from_name(p): p for p in paths}\n",
    "\n",
    "def pick_key(keys, wanted):\n",
    "    for k in wanted:\n",
    "        if k in keys: return k\n",
    "    return None\n",
    "\n",
    "def fix_dim(v, D):\n",
    "    v = np.asarray(v, np.float32).reshape(-1)\n",
    "    if v.size == D: return v\n",
    "    out = np.zeros((D,), np.float32); out[:min(D, v.size)] = v[:D]\n",
    "    return out\n",
    "\n",
    "TEXT_KEYS  = [\"h_text\",\"token_embeddings\",\"X\",\"pooled\"]\n",
    "AUDIO_KEYS = [\"h_audio\",\"hubert_embeddings\",\"audio_embeddings\",\"features\",\"hidden_states\",\"X\",\"pooled\"]\n",
    "\n",
    "def load_pooled(path, wanted_keys, expected_dim):\n",
    "    if path.endswith(\".npy\"):\n",
    "        x = np.load(path)\n",
    "        if x.ndim == 2: x = x.mean(0)\n",
    "        return fix_dim(x, expected_dim)\n",
    "    arr = np.load(path, allow_pickle=False)\n",
    "    try:\n",
    "        pk = next((k for k in arr.files if \"pooled\" in k.lower()), None)\n",
    "        if pk is not None:\n",
    "            v = arr[pk];  v = v.mean(0) if v.ndim == 2 else np.squeeze(v)\n",
    "            return fix_dim(v, expected_dim)\n",
    "        fk = pick_key(arr.files, wanted_keys)\n",
    "        if fk is None: raise KeyError(f\"None of {wanted_keys} in {path}; keys={arr.files}\")\n",
    "        X = arr[fk]\n",
    "        if X.ndim == 1: v = X\n",
    "        elif X.ndim == 2: v = X.mean(0)\n",
    "        elif X.ndim == 3: v = X.mean(1).mean(0)\n",
    "        else: raise ValueError(f\"Unexpected shape {X.shape} in {path}\")\n",
    "        return fix_dim(v, expected_dim)\n",
    "    finally:\n",
    "        if hasattr(arr, \"close\"): arr.close()\n",
    "\n",
    "# --- robust filename reader (handles UTF-16/UTF-8)\n",
    "def read_filenames_any_encoding(txt_path):\n",
    "    with open(txt_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    if data.startswith(b\"\\xff\\xfe\"):\n",
    "        enc = \"utf-16-le\"\n",
    "    elif data.startswith(b\"\\xfe\\xff\"):\n",
    "        enc = \"utf-16-be\"\n",
    "    elif data.startswith(b\"\\xef\\xbb\\xbf\"):\n",
    "        enc = \"utf-8-sig\"\n",
    "    else:\n",
    "        try:\n",
    "            data.decode(\"utf-8\"); enc = \"utf-8\"\n",
    "        except UnicodeDecodeError:\n",
    "            enc = \"latin-1\"\n",
    "    return [ln.strip() for ln in data.decode(enc).splitlines() if ln.strip()]\n",
    "\n",
    "def load_clip_bundle_with_filenames(bundle_npz_path: str, filenames_txt_path: str, expected_dim=512):\n",
    "    arr = np.load(bundle_npz_path, allow_pickle=False)\n",
    "    try:\n",
    "        if \"h_graph_nodes\" in arr.files:\n",
    "            X = arr[\"h_graph_nodes\"]          # [1,N,D] or [N,D]\n",
    "            if X.ndim == 3: X = X[0]\n",
    "        elif \"h_graph\" in arr.files and arr[\"h_graph\"].ndim == 2:\n",
    "            X = arr[\"h_graph\"]                # [N,D]\n",
    "        else:\n",
    "            raise KeyError(f\"{bundle_npz_path} needs 'h_graph_nodes' or 2D 'h_graph'; keys={arr.files}\")\n",
    "    finally:\n",
    "        if hasattr(arr, \"close\"): arr.close()\n",
    "\n",
    "    names = read_filenames_any_encoding(filenames_txt_path)   # <-- FIXED (no UnicodeDecodeError)\n",
    "    if len(names) != X.shape[0]:\n",
    "        raise ValueError(f\"Row mismatch: {bundle_npz_path} rows={X.shape[0]} vs {filenames_txt_path} lines={len(names)}\")\n",
    "\n",
    "    out = {}\n",
    "    for nm, vec in zip(names, X):\n",
    "        uid = base_id_from_name(nm)\n",
    "        out[uid] = fix_dim(vec, expected_dim)\n",
    "    return out\n",
    "\n",
    "# ---- build maps/lookups ----\n",
    "clip_vecs = {}\n",
    "clip_vecs.update(load_clip_bundle_with_filenames(HC_READTEXT_NPZ, HC_READTEXT_TXT, D_CLIP))\n",
    "clip_vecs.update(load_clip_bundle_with_filenames(PD_READTEXT_NPZ, PD_READTEXT_TXT, D_CLIP))\n",
    "\n",
    "tmap = {**map_ids(HC_TEXT_DIR),  **map_ids(PD_TEXT_DIR)}\n",
    "amap = {**map_ids(HC_AUDIO_DIR), **map_ids(PD_AUDIO_DIR)}\n",
    "\n",
    "print(\"counts — text:\", len(tmap), \"audio:\", len(amap), \"clip:\", len(clip_vecs))\n",
    "\n",
    "common = sorted(set(tmap) & set(amap) & set(clip_vecs))\n",
    "print(\"common ids:\", len(common))\n",
    "if not common:\n",
    "    raise RuntimeError(\"No overlap across modalities.\")\n",
    "\n",
    "# ---- fuse & label ----\n",
    "X_list, y_list, ids = [], [], []\n",
    "for uid in common:\n",
    "    t = load_pooled(tmap[uid], TEXT_KEYS,  D_TEXT)\n",
    "    a = load_pooled(amap[uid], AUDIO_KEYS, D_AUDIO)\n",
    "    c = clip_vecs[uid]\n",
    "    c = c / (np.linalg.norm(c) + 1e-9)   # optional L2 for CLIP\n",
    "\n",
    "    x = np.concatenate([t, a, c], -1).astype(np.float32)  # 2048-d\n",
    "    X_list.append(x)\n",
    "    y_list.append(0 if \"_hc_\" in uid.lower() else 1)      # 0=HC, 1=PD\n",
    "    ids.append(uid)\n",
    "\n",
    "X = np.stack(X_list, 0)\n",
    "y = np.array(y_list, dtype=np.int64)\n",
    "np.savez_compressed(OUT_PATH, X=X, y=y, ids=np.array(ids),\n",
    "                    D_text=np.array(D_TEXT), D_audio=np.array(D_AUDIO), D_graph=np.array(D_CLIP),\n",
    "                    note=\"ReadText: concat [text|audio|h_graph(CLIP)] per ID\")\n",
    "print(\"Saved:\", OUT_PATH, \"| X:\", X.shape, \"| HC:\", (y==0).sum(), \"PD:\", (y==1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82dea35",
   "metadata": {},
   "source": [
    "# Fusing all spontaneous embeddings together so that i can use it for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67892e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts — text: 36 audio: 36 clip: 36\n",
      "common ids: 36\n",
      "Saved: /mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/spontaneous_h_fusion/spontaneous_fused_readtext.npz | X: (36, 2048) | HC: 20 PD: 16\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob, numpy as np\n",
    "\n",
    "# ---- paths (ReadText only) ----\n",
    "HC_READTEXT_NPZ = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/h_graph_selfattn/HC_Spontaneous_Spectrogram_CLIP_features_h_graph_selfattn.npz\"\n",
    "HC_READTEXT_TXT = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/CLIP_Spectrogram_embeddings/HC_Spontaneous_Spectrogram_CLIP_filenames.txt\"\n",
    "PD_READTEXT_NPZ = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/h_graph_selfattn/PD_Spontaneous_Spectrogram_CLIP_features_h_graph_selfattn.npz\"\n",
    "PD_READTEXT_TXT = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/CLIP_Spectrogram_embeddings/PD_Spontaneous_Spectrogram_CLIP_filenames.txt\"\n",
    "\n",
    "HC_TEXT_DIR  = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/Transcript_Self_Attention/HC_Spontaneous_selfattn\"\n",
    "PD_TEXT_DIR  = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/Transcript_Self_Attention/PD_Spontaneous_selfattn\"\n",
    "HC_AUDIO_DIR = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/audio_self_attention/HC_Spontaneous_h_audio_selfattn\"\n",
    "PD_AUDIO_DIR = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/audio_self_attention/PD_Spontaneous_h_audio_selfattn\"\n",
    "\n",
    "OUT_PATH = \"/mnt/d/Roshidat_Msc_Project/Audio_parkinson/pd&Hc_multi/spontaneous_h_fusion/spontaneous_fused_readtext.npz\"\n",
    "os.makedirs(os.path.dirname(OUT_PATH), exist_ok=True)\n",
    "\n",
    "D_TEXT, D_AUDIO, D_CLIP = 768, 768, 512\n",
    "\n",
    "# ---- utils ----\n",
    "suffix_re = re.compile(\n",
    "    r\"_(?:h_text(?:_.*)?|h_audio(?:_.*)?|h_graph(?:_.*)?|h_clip(?:_.*)?|hubert_feats|audio_feats|tokens_for_selfattn)$\",\n",
    "    re.IGNORECASE,\n",
    ")\n",
    "def base_id_from_name(name: str) -> str:\n",
    "    base = os.path.splitext(os.path.basename(str(name)))[0]\n",
    "    return suffix_re.sub(\"\", base)\n",
    "\n",
    "def map_ids(folder):\n",
    "    paths = glob.glob(os.path.join(folder, \"*.npz\")) + glob.glob(os.path.join(folder, \"*.npy\"))\n",
    "    return {base_id_from_name(p): p for p in paths}\n",
    "\n",
    "def pick_key(keys, wanted):\n",
    "    for k in wanted:\n",
    "        if k in keys: return k\n",
    "    return None\n",
    "\n",
    "def fix_dim(v, D):\n",
    "    v = np.asarray(v, np.float32).reshape(-1)\n",
    "    if v.size == D: return v\n",
    "    out = np.zeros((D,), np.float32); out[:min(D, v.size)] = v[:D]\n",
    "    return out\n",
    "\n",
    "TEXT_KEYS  = [\"h_text\",\"token_embeddings\",\"X\",\"pooled\"]\n",
    "AUDIO_KEYS = [\"h_audio\",\"hubert_embeddings\",\"audio_embeddings\",\"features\",\"hidden_states\",\"X\",\"pooled\"]\n",
    "\n",
    "def load_pooled(path, wanted_keys, expected_dim):\n",
    "    if path.endswith(\".npy\"):\n",
    "        x = np.load(path)\n",
    "        if x.ndim == 2: x = x.mean(0)\n",
    "        return fix_dim(x, expected_dim)\n",
    "    arr = np.load(path, allow_pickle=False)\n",
    "    try:\n",
    "        pk = next((k for k in arr.files if \"pooled\" in k.lower()), None)\n",
    "        if pk is not None:\n",
    "            v = arr[pk];  v = v.mean(0) if v.ndim == 2 else np.squeeze(v)\n",
    "            return fix_dim(v, expected_dim)\n",
    "        fk = pick_key(arr.files, wanted_keys)\n",
    "        if fk is None: raise KeyError(f\"None of {wanted_keys} in {path}; keys={arr.files}\")\n",
    "        X = arr[fk]\n",
    "        if X.ndim == 1: v = X\n",
    "        elif X.ndim == 2: v = X.mean(0)\n",
    "        elif X.ndim == 3: v = X.mean(1).mean(0)\n",
    "        else: raise ValueError(f\"Unexpected shape {X.shape} in {path}\")\n",
    "        return fix_dim(v, expected_dim)\n",
    "    finally:\n",
    "        if hasattr(arr, \"close\"): arr.close()\n",
    "\n",
    "# --- robust filename reader (handles UTF-16/UTF-8)\n",
    "def read_filenames_any_encoding(txt_path):\n",
    "    with open(txt_path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    if data.startswith(b\"\\xff\\xfe\"):\n",
    "        enc = \"utf-16-le\"\n",
    "    elif data.startswith(b\"\\xfe\\xff\"):\n",
    "        enc = \"utf-16-be\"\n",
    "    elif data.startswith(b\"\\xef\\xbb\\xbf\"):\n",
    "        enc = \"utf-8-sig\"\n",
    "    else:\n",
    "        try:\n",
    "            data.decode(\"utf-8\"); enc = \"utf-8\"\n",
    "        except UnicodeDecodeError:\n",
    "            enc = \"latin-1\"\n",
    "    return [ln.strip() for ln in data.decode(enc).splitlines() if ln.strip()]\n",
    "\n",
    "def load_clip_bundle_with_filenames(bundle_npz_path: str, filenames_txt_path: str, expected_dim=512):\n",
    "    arr = np.load(bundle_npz_path, allow_pickle=False)\n",
    "    try:\n",
    "        if \"h_graph_nodes\" in arr.files:\n",
    "            X = arr[\"h_graph_nodes\"]          # [1,N,D] or [N,D]\n",
    "            if X.ndim == 3: X = X[0]\n",
    "        elif \"h_graph\" in arr.files and arr[\"h_graph\"].ndim == 2:\n",
    "            X = arr[\"h_graph\"]                # [N,D]\n",
    "        else:\n",
    "            raise KeyError(f\"{bundle_npz_path} needs 'h_graph_nodes' or 2D 'h_graph'; keys={arr.files}\")\n",
    "    finally:\n",
    "        if hasattr(arr, \"close\"): arr.close()\n",
    "\n",
    "    names = read_filenames_any_encoding(filenames_txt_path)   # <-- FIXED (no UnicodeDecodeError)\n",
    "    if len(names) != X.shape[0]:\n",
    "        raise ValueError(f\"Row mismatch: {bundle_npz_path} rows={X.shape[0]} vs {filenames_txt_path} lines={len(names)}\")\n",
    "\n",
    "    out = {}\n",
    "    for nm, vec in zip(names, X):\n",
    "        uid = base_id_from_name(nm)\n",
    "        out[uid] = fix_dim(vec, expected_dim)\n",
    "    return out\n",
    "\n",
    "# ---- build maps/lookups ----\n",
    "clip_vecs = {}\n",
    "clip_vecs.update(load_clip_bundle_with_filenames(HC_READTEXT_NPZ, HC_READTEXT_TXT, D_CLIP))\n",
    "clip_vecs.update(load_clip_bundle_with_filenames(PD_READTEXT_NPZ, PD_READTEXT_TXT, D_CLIP))\n",
    "\n",
    "tmap = {**map_ids(HC_TEXT_DIR),  **map_ids(PD_TEXT_DIR)}\n",
    "amap = {**map_ids(HC_AUDIO_DIR), **map_ids(PD_AUDIO_DIR)}\n",
    "\n",
    "print(\"counts — text:\", len(tmap), \"audio:\", len(amap), \"clip:\", len(clip_vecs))\n",
    "\n",
    "common = sorted(set(tmap) & set(amap) & set(clip_vecs))\n",
    "print(\"common ids:\", len(common))\n",
    "if not common:\n",
    "    raise RuntimeError(\"No overlap across modalities.\")\n",
    "\n",
    "# ---- fuse & label ----\n",
    "X_list, y_list, ids = [], [], []\n",
    "for uid in common:\n",
    "    t = load_pooled(tmap[uid], TEXT_KEYS,  D_TEXT)\n",
    "    a = load_pooled(amap[uid], AUDIO_KEYS, D_AUDIO)\n",
    "    c = clip_vecs[uid]\n",
    "    c = c / (np.linalg.norm(c) + 1e-9)   # optional L2 for CLIP\n",
    "\n",
    "    x = np.concatenate([t, a, c], -1).astype(np.float32)  # 2048-d\n",
    "    X_list.append(x)\n",
    "    y_list.append(0 if \"_hc_\" in uid.lower() else 1)      # 0=HC, 1=PD\n",
    "    ids.append(uid)\n",
    "\n",
    "X = np.stack(X_list, 0)\n",
    "y = np.array(y_list, dtype=np.int64)\n",
    "np.savez_compressed(OUT_PATH, X=X, y=y, ids=np.array(ids),\n",
    "                    D_text=np.array(D_TEXT), D_audio=np.array(D_AUDIO), D_graph=np.array(D_CLIP),\n",
    "                    note=\"ReadText: concat [text|audio|h_graph(CLIP)] per ID\")\n",
    "print(\"Saved:\", OUT_PATH, \"| X:\", X.shape, \"| HC:\", (y==0).sum(), \"PD:\", (y==1).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sheedah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
